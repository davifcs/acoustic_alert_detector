gpus: 1 # number of gpus
workers: 0 # number of cpu threads
model:
  type: "convolutional"
  cnn:
    dim: 2
  transformer:
    embed_dim: 16
    hidden_dim: 16
    num_heads: 2
    patch_size: 8
    num_channels: 1
    num_patches: 40
    num_classes: 2
    dropout: 0.2
learning_rate: 0.001 # initial learning rate
weight_decay: 0 # optimizer weight decay
epochs: 1
batch_size: 64
datasets:
  main: 'audioset'
  support: 'esc50'
  audioset:
    annotations_file: './data/AudioSet/balanced_train_segments/filtered_balanced_train_segments.csv'
    audio_dir: './data/AudioSet/balanced_train_segments/'
  esc50:
    annotations_file: './data/ESC-50-master/meta/esc50.csv'
    audio_dir: './data/ESC-50-master/audio/'
    folds: [ 1, 2, 3, 4, 5 ]
  urbansound8k:
    annotations_file: './data/UrbanSound8K/metadata/UrbanSound8K.csv'
    audio_dir: './data/UrbanSound8K/audio/'
    folds: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ]
runs_dir : './runs/exp'
target_size: 1.5 # target size in seconds
target_sr: 22050 # target sample rate
transforms:
  type: "mel_spectrogram"
  mel_spectrogram:
    n_fft: 2048
    hop_length: 512
    n_mels: 64
    power: 2 # power
    center: False
    normalized: False,
    mel_scale: "slaney"
  mfcc:
    n_mfcc: 40
    dct_type: 2
    norm: 'ortho'